Hierarchical clustering is a clustering tool used in unsupervised machine learning and data analysis where data points are grouped into hierarchical structures or a tree-like representation of clusters. By starting with single data points and gradually combining them into larger clusters based on their similarities, it tries to establish a hierarchy of clusters. Hierarchical clustering can be represented using tree diagrams called a dendrograms, which provides information about links between clusters at different levels of granularity.

The task was completed in Jupyter Notebook using the Iris data set from which two features were chosen to use in the exercise and scale the data. Having used used single and complete linkages and Euclidean and Cityblock distance metrics, dendrograms for the different combinations of these were printed. One dendrogram was selected to proceed with the exercise and then a fixed number of clusters was picked based on this dendrogram choice. Agglomerative hierarchical clustering was run with that number of clusters. Lastly, the clusters were verified using the silhouette score and the confidence in the clustering solution was reported.
